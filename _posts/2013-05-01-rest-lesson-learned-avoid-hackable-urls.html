---
layout: post
title: "REST lesson learned: Avoid hackable URLs"
date: 2013-05-01 10:29 UTC
tags: [Software Design, Services, REST]
---
{% include JB/setup %}

<div id="post">
	<p>
		<em>Avoid hackable URLs if you are building a HATEOAS API.</em>
	</p>
	<p>
		This is a <a href="http://blog.ploeh.dk/2013/04/29/rest-lessons-learned">lesson about REST API design that I learned while building non-trivial REST APIs</a>. If you provide a full-on <a href="http://martinfowler.com/articles/richardsonMaturityModel.html">level 3</a> REST API, consider avoiding hackable URLs.
	</p>
	<p>
		<strong>Hackable URLs</strong>
	</p>
	<p>
		A <em>hackable URL</em> is a URL where there's a clear pattern or template for constructing the URL. As an example, if I present to you the URL <code>http://foo.ploeh.dk/products/1234</code>, it's easy to guess that this is a resource representing a product with the SKU of <em>1234</em>. If you know the SKU of another product, it's easy to 'hack' the URL to produce e.g. <code>http://foo.ploeh.dk/products/5678</code>.
	</p>
	<p>
		That's a really nice feature of your API if you are doing a <a href="http://martinfowler.com/articles/richardsonMaturityModel.html">level 1 or 2</a> API, but for a <a href="http://en.wikipedia.org/wiki/HATEOAS">HATEOAS</a> API, this defies the purpose.
	</p>
	<p>
		<strong>The great divide</strong>
	</p>
	<p>
		Please notice that the shift from level 2 to level 3 RESTful APIs mark a fundamental shift in the way you should approach URL design.
	</p>
	<p>
		<img src="/content/binary/great-divide-between-richardson-level-2-and-3.png">
	</p>
	<p>
		Hackable URLs are great for level 1 and 2 APIs because the way you (as a client) are told to construct URLs is by assembling them from templates. As <a href="http://msdn.microsoft.com/en-us/library/windowsazure/dd179370.aspx">an example</a>, the Windows Azure REST APIs explicitly instruct you to construct the URL in a particular way: the URL to get BLOB container properties is <code>https://myaccount.blob.core.windows.net/mycontainer?restype=container</code>, where you should replace <em>myaccount</em> with your account name, and <em>mycontainer</em> with your container name. While code aesthetics are subjective, it's not even a particularly <a href="http://en.wikipedia.org/wiki/Clean_URL">clean URL</a>, but it's easy enough to produce. The URL template is part of the contract, which puts the Windows Azure API solidly at level 2 of the Richardson Maturity Model. If I were designing a level 1 or 2 API, I'd make sure to make URLs hackable, too.
	</p>
	<p>
		However, if you're building a level 3 API, hypermedia is king. Clients are expected to <em>follow links</em>. The addresses of resources are <em>not</em> published as having a particular template; instead, clients must follow semantic links in order to arrive at the desired resource(s). When hypermedia is the engine of application state, it's no good if the client can short-circuit the application flow by 'hacking' URLs. It may leave the application in an inconsistent state if it tries to do that.
	</p>
	<p>
		Hackable URLs are great for level 1 and 2 APIs, but counter-productive for level 3 APIs.
	</p>
	<p>
		<strong>Evolving URLs</strong>
	</p>
	<p>
		One of the main attractions of building a level 3 RESTful API is that it's easier to evolve. Exactly because URL templates are <em>not</em> part of the contract, you can decide to change the URL structure when evolving your API.
	</p>
	<p>
		Imagine that the first version of your API has an (internal) URL template like <code>/orders/{customerId}</code>, so that the example URL <code>http://foo.ploeh.dk/orders/1234</code> is the address of the order history for customer <em>1234</em>. However, in version 2 of your API, you realize that this way of thinking is still too RPC-like, and you'd rather prefer <code>/customers/{customerId}/order</code>, e.g. <code>http://foo.ploeh.dk/customers/1234/orders</code>.
	</p>
	<p>
		With a level 3 RESTful API, you can change your internal URL templates, and as long as you keep providing links, clients following links will not notice the difference. However, if clients are 'hacking' your URLs, their applications may stop working if you change URL templates.
	</p>
	<p>
		<strong>Keep clients safe</strong>
	</p>
	<p>
		In the end, HATEOAS is about encapsulation: make it easy for the client to do the right thing, and make it hard for the client to do the wrong thing. Following links will make clients more robust, because they will be able to handle changes in the API. Making it easy for clients to follow links is one side of designing a good API, but the other side is important too: make it difficult for clients to <em>not</em> follow links: make it difficult for clients to 'hack' URLs.
	</p>
	<p>
		The services I've helped design so far are level 3 APIs, but they still used hackable URLs. One reason for that was that this is the default in the implementation platform we used (<a href="http://www.asp.net/web-api">ASP.NET Web API</a>); another reason was that I thought it would be easier for me and the rest of the development team if the URLs were human-readable. Today, I think this decision was a mistake.
	</p>
	<p>
		What's the harm of supplying human-readable URLs for a level 3 RESTful API? After all, if a client only follows links, the values of the URLs shouldn't matter.
	</p>
	<p>
		Indeed, <em>if</em> the client only follows links. However, clients are created by human developers, and humans often take the road of least resistance. While there are long-time benefits (robustness) from following links, it <em>is</em> more work in the short term. The API team and I repeatedly experienced that the developers consuming our APIs had 'hacked' our URLs; when we changed our URL templates, their clients broke and they complained. Even though we had tried to explicitly tell them that they <em>must</em> follow links, they didn't. While we <em>never</em> documented our URL templates, they were simply too easy to guess from pure extrapolation.
	</p>
	<p>
		<strong>Opaque URLs</strong>
	</p>
	<p>
		In the future, I plan to make URLs opaque when building level 3 APIs. Instead of <code>http://foo.ploeh.dk/customers/1234/orders</code>, I'm going to make it <code>http://foo.ploeh.dk/DC884298C70C41798ABE9052DC69CAEE</code>, and instead of <code>http://foo.ploeh.dk/products/2345</code>, I'm going to make it <code>http://foo.ploeh.dk/598CB0CAC30646E1BB768596BFE91F2C</code>, and so on.
	</p>
	<p>
		Obviously, that means that my API will have to maintain some sort of two-way lookup table that can map DC884298C70C41798ABE9052DC69CAEE to a request for customer <em>1234</em>'s orders, 598CB0CAC30646E1BB768596BFE91F2C to request for product <em>2345</em>, but that's trivial to implement.
	</p>
	<p>
		It puts a small burden on the server(s), but effectively stops client developers from shooting themselves in their feet.
	</p>
	<p>
		<strong>Summary</strong>
	</p>
	<p>
		Hackable URLs are a good idea if you are building a web site, or a level 1 or 2 REST API, but unless you know that all client developers are enthusiastic RESTafarians, consider producing opaque URLs for level 3 REST APIs.
	</p>
</div>

<div id="comments">
<hr>
<h2 id="comments-header">Comments</h2>
	<div class="comment">
		<div class="comment-author">
			<a href="https://github.com/JontyMC">Jon Curtis</a>
		</div>
		<div class="comment-content">
			<p>
				I understand the benefits of the idea that clients must follow links, I just can't see how it would work in reality. Say you are building a website to display products and you are consuming a rest API, how do you support deep linking to individual products? OK, you can either use the same URL as the underlying API or encode it in, but what are you expected to do if the API changes it's links? Redirect the user to your home page? What if you want to display information from 2 or more resources on the same webpage?
			</p>
		</div>
		<div class="comment-date">2013-05-15 8:04 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author">
			<a href="http://blog.ploeh.dk/">Mark Seemann</a>
		</div>
		<div class="comment-content">
			<p>
				First of all, keep in mind that while it can be helpful to think about REST design principles in terms of "how would I design this if it was a web site", a REST API is <em>not</em> a web site.
			</p>
			<p>
				You can do deep linking in your web site, but why would you want to do 'deep linking' for an API? These are two different concerns.
			</p>
			<p>
				It's very common to create a web site where each page calls many individual services. This can be done either from the web server (e.g. from ASP.NET or similar), or from the browser as AJAX calls. This is commonly known as <em>mash-up architecture</em>, because the GUI is really just a mash-up of service data. Amazon.com works that way. You can still deep link to a web page; it's the web page's responsibility to figure out which services to call with what parameters.
			</p>
			<p>
				That said, as described in the <a href="http://amzn.to/YFnkRg">RESTful Web Services Cookbook</a>, you should serve <a href="http://www.w3.org/Provider/Style/URI.html">cool URLs</a>, so if you ever decide to change your internal URI template, you should leave a <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3.2">301 (Moved Permanently)</a> behind at the old URL. This would enable a client that once bookmarked a resource to follow the redirect to the new address.
			</p>
		</div>
		<div class="comment-date">2013-05-15 9:11 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author">
			<a href="https://github.com/JontyMC">Jon Curtis</a>
		</div>
		<div class="comment-content">
			<p>
				When you say "it's the web page's responsibility to figure out which services to call", that's what I'm getting at, how would the client do that?
			</p>
			<p>
				I'm guessing one way would be to cache links followed and update them on 301s or "re-follow" on 404s. So, say you wanted a web page displaying "product/24", you might:
			</p>
			<ul>
				<li>GET the REST endpoint</li>
				<li>GET product catalogue URL from response</li>
				<li>GET product URL from response</li>
				<li>Cache the product URL against the website product URL</li>
				<li>Subsequent requests hit the cached URL</li>
			</ul>
			<p>
				Then if the product URL changes, if the response is 301, you simply update the cache. If the response is 404 then you'd redo the above steps.
			</p>
			<p>
				I'm just thinking this through, is the above a "standard" approach for creating rest clients?
			</p>
		</div>
		<div class="comment-date">2013-05-15 12:04 UTC</div>
	</div>
</div>