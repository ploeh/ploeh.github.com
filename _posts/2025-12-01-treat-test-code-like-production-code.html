---
layout: post
title: "Treat test code like production code"
description: "You have to read and maintain test code, too."
date: 2025-12-01 15:03 UTC
tags: [Code, Unit Testing]
---
{% include JB/setup %}

<div id="post">
    <p>
        <em>{{ page.description }}</em>
    </p>
    <p>
        I don't think I've previously published an article with the following simple message, which is clearly an omission on my part. Better late than never, though.
    </p>
    <p>
        <em>Treat test code like production code.</em>
    </p>
    <p>
        You should apply the same coding standards to test code as you do to production code. You should make sure the code is readable, well-factored, goes through review, etc., just like your production code.
    </p>
    <h3 id="96bb9c9eb94546b498d619d2a46d6e98">
        Test mess <a href="#96bb9c9eb94546b498d619d2a46d6e98">#</a>
    </h3>
    <p>
        It's not uncommon to encounter test code that has received a stepmotherly treatment. Such test code may still pay lip service to an organization's overall coding standards by having correct indents, placement of brackets, and other superficial signs of care. You don't have to dig deep, however, before you discover that the quality of the test code leaves much to be desired.
    </p>
    <p>
        The most common problem is a disregard for the <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">DRY principle</a>. Duplication abound. It's almost as though people feel unburdened by the shackles of good software engineering practices, and as result relish in the freedom to copy and paste.
    </p>
    <p>
        That freedom is, however, purely illusory. We'll return to that shortly.
    </p>
    <p>
        Perhaps the second-most common category of poor coding practices applied to test code is the high frequency of <a href="https://www.bitnative.com/2012/10/22/kill-the-zombies-in-your-code/">Zombie Code</a>. Commented-out code is common.
    </p>
    <p>
        Other, less frequent examples of bad practices include use of arbitrary waits instead of proper thread synchronization, <a href="/2019/02/04/how-to-get-the-value-out-of-the-monad">unwrapping of monadic values</a>, including calling <a href="https://learn.microsoft.com/dotnet/api/system.threading.tasks.task-1.result">Task.Result</a> instead of properly awaiting a value, and so on.
    </p>
    <p>
        I'm sure that you can think of other examples.
    </p>
    <h3 id="8aab547e039d4b3f8fa5cf095fd60dcb">
        Why good code is important <a href="#8aab547e039d4b3f8fa5cf095fd60dcb">#</a>
    </h3>
    <p>
        I think that I can understand why people treat test code as a second-class citizen. It seems intuitive, although the intuition is wrong. Nevertheless, I think it goes like this: Since the test code doesn't go into production, it's seen as less important. And as we shall see below, there are, indeed, a few areas where you can safely cut corners when it comes to test code.
    </p>
    <p>
        As a general rule, however, it's a bad idea to slack on quality in test code.
    </p>
    <p>
        The reason lies in why we even have coding standards and design principles in the first place. Here's a hint: It's not to placate the computer.
    </p>
    <blockquote>
        <p>
            "Any fool can write code that a computer can understand. Good programmers write code that humans can understand."
        </p>
        <footer><cite><a href="/ref/refactoring">Refactoring</a></cite>, Martin Fowler, 1999, ch. 1, p. 15</footer>
    </blockquote>
    <p>
        The reason we do our best to write code of good quality is that if we don't, it's going to make our work more difficult in the future. Either our own, or someone else's. But frequently, our own.
    </p>
    <p>
        Forty (or fifty?) years of literature on good software development practices grapple with this fundamental problem. This is why my most recent book is called <a href="/2021/06/14/new-book-code-that-fits-in-your-head">Code That Fits in Your Head</a>. We apply software engineering heuristics and care about architecture because we know that if we fail to structure the code well, our mission is in jeopardy: We will not deliver on time, on budget, or with working features.
    </p>
    <p>
        Once we understand this, we see how this applies to test code, too. If you have good test coverage, you will likely have a substantial amount of test code. You need to maintain this part of the code base too. The best way to do so is to treat it like your production code. Apply the same standards and design principles to test code as you do to your production code. This especially means keeping test code DRY.
    </p>
    <h3 id="a2931e61642a4861be94f2f4e48fe624">
        Test-specific practices <a href="#a2931e61642a4861be94f2f4e48fe624">#</a>
    </h3>
    <p>
        Since test code has a specialized purpose, you'll run into problems unique to that space. How should you structure a unit test? How should you organize them? How should you name them? How do you make them deterministic?
    </p>
    <p>
        Fortunately, thoughtful people have collected and systematized their experience. The absolute most comprehensive such collection is <a href="/ref/xunit-patterns">xUnit Test Patterns</a>, which has been around since 2007. Nothing in that book invalidates normal coding practices. Rather, it suggests specializations of good practices that apply to test code.
    </p>
    <p>
        You may run into the notion that tests should be <a href="http://blog.jayfields.com/2006/05/dry-code-damp-dsls.html">DAMP</a> rather than DRY. If you expand the acronym, however, it stands for Descriptive And Meaningful Phrases, and you may realize that it's a desired quality of code independent of whether or not you repeat yourself. (Even the linked article fails, in my opinion, to erect a convincing dichotomy. Its notion of DRY is clearly not the one normally implied.) I think of the DAMP notion as related to <a href="/ref/ddd">Domain-Driven Design</a>, which is another thematic take on making code fit in your head.
    </p>
    <p>
        For a few years, however, I did, too, believe that copy-and-paste was okay in test code, but have long since learned that duplication slows you down in test code for exactly the same reason that it hurts in 'real' code. One simple change leads to <a href="https://en.wikipedia.org/wiki/Shotgun_surgery">Shotgun Surgery</a>; many tests break, and you have to fix each one individually.
    </p>
    <h3 id="3db515539ace45f6a29dd54b6de90f78">
        Dispensations <a href="#3db515539ace45f6a29dd54b6de90f78">#</a>
    </h3>
    <p>
        All the same, there are exceptions to the general rule. In certain, well-understood ways, you can treat your test code with less care than production code.
    </p>
    <p>
        Specifically, assuming that test code remains undeployed, you can skip certain security practices. You may, for example, hard-code test-only passwords directly in the tests. The code base that accompanies <a href="/code-that-fits-in-your-head">Code That Fits in Your Head</a> contains an example of that.
    </p>
    <p>
        You may also skip input validation steps, since you control the input for each test.
    </p>
    <p>
        In my experience, security is the dominating exemption from the rule, but there may be other language- or platform-specific details where deviating from normal practices is warranted for test code.
    </p>
    <p>
        One example may be in .NET, where <a href="https://learn.microsoft.com/dotnet/fundamentals/code-analysis/quality-rules/ca2007">a static code analysis rule may insist that you call ConfigureAwait</a>. This rule is intended for library code that may run in arbitrary environments. When code runs in a unit-testing environment, on the other hand, the context is already known, and this rule can be dispensed with.
    </p>
    <p>
        Another example is that in <a href="https://www.haskell.org/">Haskell</a> GHC may complain about <a href="https://wiki.haskell.org/index.php?title=Orphan_instance">orphan instances</a>. In test code, it may occasionally be useful to give an existing type a new instance, most commonly an <a href="https://hackage-content.haskell.org/package/QuickCheck/docs/Test-QuickCheck.html#t:Arbitrary">Arbitrary</a> instance. While you can also get around this problem with <a href="/2019/09/02/naming-newtypes-for-quickcheck-arbitraries">well-named newtypes</a>, you may also decide that orphan instances are no problem in a test code base, since you don't have to export the test modules as reusable libraries.
    </p>
    <h3 id="1e6560fee36e4944bee9f2bdf9fea64c">
        Conclusion <a href="#1e6560fee36e4944bee9f2bdf9fea64c">#</a>
    </h3>
    <p>
        You should treat test code like production code. The coding standards that apply to production code should also apply to test code. If you follow the DRY principle for production code, you should also follow the DRY principle in the test code base.
    </p>
    <p>
        The reason is that most coding standards and design principles exist to make code maintainability easier. Since test code is also code, this still applies.
    </p>
    <p>
        There are a few exception, most notably in the area of security, assuming that the test code is never deployed to production.
    </p>
</div>

<div id="comments">
    <hr>
    <h2 id="comments-header">
        Comments
    </h2>
    <div class="comment" id="f28942cb8994436b97ed8883426b2992">
        <div class="comment-author"><a href="https://github.com/soenderby">Jakob SÃ¸nderby Kristensen</a> <a href="f28942cb8994436b97ed8883426b2992">#</a></div>
        <div class="comment-content">
            <p>
                What are your thoughts on abstractions in test code? 
                I have never found it necessary, but have at times been tempted to create abstractions in my test projects that themselves would require testing.  
                This is usually only a consideration in projects with a complex test setup or very large test suites.  
            </p>
            <p>
                I am also curious about your thoughts on adding additional logic to the implementation code with the sole purpose of making it easier to test.  
                As an example: Adding a method to a class that makes it a more complete abstraction, but that method is never called in production code.  
            </p>
            <p>
                My own opinion is split between keeping tests readable and potentially easier to maintain by using reusable abstractions, and keeping them simple and robust.  
            </p>
        </div>
        <div class="comment-date">2025-12-05 13:02 UTC</div>
    </div>
</div>