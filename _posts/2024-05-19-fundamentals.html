---
layout: post
title: "Fundamentals"
description: "How to stay current with technology progress."
date: 2024-05-19 6:27 UTC
tags: [Productivity]
---
{% include JB/setup %}

<div id="post">
    <p>
        <em>{{ page.description }}</em>
    </p>
    <p>
        A long time ago, I landed my dream job. My new employer was a consulting company, and my role was to be the resident <a href="https://en.wikipedia.org/wiki/Microsoft_Azure">Azure</a> expert. Cloud computing was still in its infancy, and there was a good chance that I might be able to establish myself as a leading regional authority on the topic.
    </p>
    <p>
        As part of the role, I was supposed to write articles and give presentations to show how to solve various problems with Azure. I dug in with fervour, writing sample code bases and even <a href="http://msdn.microsoft.com/en-us/magazine/gg983487.aspx">an MSDN Magazine article</a>. To my surprise, after half a year I realized that I was bored.
    </p>
    <p>
        I'd already spent more than a decade learning new technology, and I knew that I was good at it. For instance, I worked five years for Microsoft Consulting Services, and a dirty little secret of this kind of role is that, although you're sold as an expert in some new technology, you're often only a few weeks ahead of your customer. For example, I was once engaged as a <a href="https://en.wikipedia.org/wiki/Windows_Workflow_Foundation">Windows Workflow Foundation</a> expert at a time when it was still in beta. No-one had years of experience with that technology, but I was still expected to know much more about it than my customer.
    </p>
    <p>
        I had lots of engagements like that, and they usually went well. I've always been good at cramming, and as a consultant you're also unencumbered by all the daily responsibilities and politics that often occupy the time and energy of regular employees. The point being that while I'm decent at learning new stuff, the role of being a consultant also facilitates that sort of activity.
    </p>
    <p>
        After more then a decade of learning new frameworks, new software libraries, new programming languages, new tools, new online services, it turned out that I was ready for something else. After spending a few months learning Azure, I realized that I'd lost interest in that kind of learning. When investigating a new Azure SDK, I'd quickly come to the conclusion that, <em>oh, this is just another object-oriented library</em>. There are these objects, and you call this method to do that, etc. That's not to say that learning a specific technology is a trivial undertaking. The worse the design, the more difficult it is to learn.
    </p>
    <p>
        Still, after years of learning new technologies, I'd started recognizing certain patterns. Perhaps, I thought, well-designed technologies are based on some fundamental ideas that may be worth learning instead.
    </p>
    <h3 id="ac37913a2b8248e6b51d4506c2da0481">
        Staying current <a href="#ac37913a2b8248e6b51d4506c2da0481">#</a>
    </h3>
    <p>
        A common lament among software developers is that the pace of technology is so overwhelming that they can't keep up. This is true. You can't keep up.
    </p>
    <p>
        There will always be something that you don't know. In fact, most things you don't know. This isn't just a condition isolated to technology. The sum total of all human knowledge is so vast that you can't know it all. What you will learn, even after a lifetime of diligent study, will be a nanoscopic fraction of all human knowledge - even of everything related to software development. You can't stay current. Get used to it.
    </p>
    <p>
        A more appropriate question is: <em>How do I keep my skill set relevant?</em>
    </p>
    <p>
        Assuming that you wish to stay employable in some capacity, it's natural to be concerned how your mad <a href="https://en.wikipedia.org/wiki/Adobe_Flash">Flash</a> skillz will land you the next gig.
    </p>
    <p>
        Trying to keep abreast with all new technologies in your field is likely to lead to burnout. Rather, put yourself in a position so that you can quickly learn the things that you need to learn for the next job.
    </p>
    <h3 id="c529c0131b284fe1bca42bec0663fc8e">
        Study fundamentals, rather than specifics <a href="#c529c0131b284fe1bca42bec0663fc8e">#</a>
    </h3>
    <p>
        Those many years ago, I realized that it'd be a better investment of my time to study fundamentals. Often, once you have some foundational knowledge, you can apply it in many circumstances. Your general knowledge will enable you to get quickly up to speed with specific technologies.
    </p>
    <p>
        Success isn't guaranteed, but knowing fundamentals increases your chances.
    </p>
    <p>
        This may still seem too abstract. Which fundamentals should you learn?
    </p>
    <p>
        In the remainder of this article, I'll give you some examples. The following collection of general programmer knowledge spans software engineering, computer science, broad ideas, but also specific tools. I only intend this set of examples to serve as inspiration. The list isn't complete, nor does it constitute a minimum of what you should learn.
    </p>
    <p>
        If you have other interests, you may put together your own research programme. What follows here are just some examples of fundamentals that I've found useful during my career.
    </p>
    <p>
        A criterion, however, for constituting foundational knowledge is that you should be able to apply that knowledge in a wide variety of contexts. The fundamental should not be tied to a particular programming language, platform, or operating system.
    </p>
    <h3 id="4f474189809f4d53b447b4005cef1bfd">
        Design patterns <a href="#4f474189809f4d53b447b4005cef1bfd">#</a>
    </h3>
    <p>
        Perhaps the first foundational notion that I personally encountered was that of <em>design patterns</em>. As the Gang of Four wrote in the book, a design pattern is an abstract description of a solution that has been observed 'in the wild', more than once, individually evolved.
    </p>
    <p>
        Please pay attention to the causality. A design pattern isn't prescriptive, but descriptive. It's an observation that a particular code organisation tends to solve a particular problem.
    </p>
    <p>
        There are lots of misconceptions related to design patterns. One of them is that the 'library of patterns' is finite, and more or less constrained to the patterns included in the original book.
    </p>
    <p>
        There are, however, many more patterns. To illustrate how much wider this area is, here's a list of some patterns books in my personal library:
    </p>
    <ul>
        <li><a href="/ref/dp">Design Patterns</a></li>
        <li><a href="/ref/plopd3">Pattern Languages of Program Design 3</a></li>
        <li><a href="/ref/peaa">Patterns of Enterprise Application Architecture</a></li>
        <li><a href="/ref/eip">Enterprise Integration Patterns</a></li>
        <li><a href="/ref/xunit-patterns">xUnit Test Patterns</a></li>
        <li><a href="/ref/service-design-patterns">Service Design Patterns</a></li>
        <li><a href="/ref/implementation-patterns">Implementation Patterns</a></li>
        <li><a href="/ref/rest-cookbook">RESTful Web Services Cookbook</a></li>
        <li><a href="/ref/antipatterns">AntiPatterns</a></li>
    </ul>
    <p>
        In addition to these, there are many more books in my library that are patterns-adjacent, including <a href="/dippp">one of my own</a>. The point is that software design patterns is a vast topic, and it pays to know at least the most important ones.
    </p>
    <p>
        A design pattern fits the criterion that you can apply the knowledge independent of technology. The original GoF book has examples in <a href="https://en.wikipedia.org/wiki/C%2B%2B">C++</a> and <a href="https://en.wikipedia.org/wiki/Smalltalk">Smalltalk</a>, but I've found that they apply well to C#. Other people employ them in their <a href="https://www.java.com/">Java</a> code.
    </p>
    <p>
        Knowing design patterns not only helps you design solutions. That knowledge also enables you to recognize patterns in existing libraries and frameworks. It's this fundamental knowledge that makes it easier to learn new technologies.
    </p>
    <p>
        Often (although not always) successful software libraries and frameworks tend to follow known patterns, so if you're aware of these patterns, it becomes easier to learn such technologies. Again, be aware of the causality involved. I'm not claiming that successful libraries are explicitly designed according to published design patterns. Rather, some libraries become successful because they offer good solutions to certain problems. It's not surprising if such a good solution falls into a pattern that other people have already observed and recorded.
    </p>
    <p>
        This was my experience when I started to learn the details of Azure. Many of those SDKs and APIs manifested various design patterns, and once I'd recognized a pattern it became much easier to learn the rest.
    </p>
    <p>
        The idea of design patterns, particularly object-oriented design patterns, have its detractors, too. Let's visit that as the next set of fundamental ideas.
    </p>
    <h3 id="c44e7624ea3e4cef9485522146d17a6d">
        Functional programming abstractions <a href="#c44e7624ea3e4cef9485522146d17a6d">#</a>
    </h3>
    <p>
        As I'm writing this, yet another Twitter thread pokes fun at object-oriented design (OOD) patterns as being nothing be a published collection of workarounds for the shortcomings of object orientation. The people who most zealously pursue that agenda tends to be functional programmers.
    </p>
    <p>
        Well, I certainly like functional programming (FP) better than OOD too, but rather than poking fun at OOD, I'm more interested in <a href="/2018/03/05/some-design-patterns-as-universal-abstractions">how design patterns relate to universal abstractions</a>. I also believe that FP has shortcomings of its own, but I'll have more to say about that in a future article.
    </p>
    <p>
        Should you learn about <a href="/2017/10/06/monoids">monoids</a>, <a href="/2018/03/22/functors">functors</a>, <a href="/2022/03/28/monads">monads</a>, <a href="/2019/04/29/catamorphisms">catamorphisms</a>, and so on?
    </p>
    <p>
        Yes you should, because these ideas also fit the criterion that the knowledge is technology-independent. I've used my knowledge of these topics in <a href="https://www.haskell.org/">Haskell</a> (hardly surprising) and <a href="https://fsharp.org/">F#</a>, but also in C# and <a href="https://www.python.org/">Python</a>. The various <a href="https://en.wikipedia.org/wiki/Language_Integrated_Query">LINQ</a> methods are really just well-known APIs associated with, you guessed it, functors, monads, monoids, and catamorphisms.
    </p>
    <p>
        Once you've learned these fundamental ideas, it becomes easier to learn new technologies. This has happened to me multiple times, for example in the context of property-based testing libraries. Once I realize that an API gives rise to a monad, say, I know that certain functions must be available. I also know how I should best compose larger code blocks from smaller ones.
    </p>
    <p>
        Must you know all of these concepts before learning, say, F#? No, not at all. Rather, a language like F# is a great avenue to learn these fundamentals. There's a firts time to learn anything, and you need to start somewhere. Rather, the point is that once you know these concepts, it becomes easier to learn the next thing.
    </p>
    <p>
        If, for example, you already know what a monad is when learning F#, picking up the idea behind <a href="https://learn.microsoft.com/dotnet/fsharp/language-reference/computation-expressions">computation expressions</a> is easy once you realize that it's just a compiler-specific way to enable syntactic sugaring of monadic expressions. You can learn how computation expressions work without that knowledge, too; it's just harder.
    </p>
    <p>
        This is a recurring theme with many of these examples. You can learn a particular technology without knowing the fundamentals, but you'll have to put in more time to do that.
    </p>
    <h3 id="02c8fb3f6fe74fb9bffda719122c60a9">
        SQL <a href="#02c8fb3f6fe74fb9bffda719122c60a9">#</a>
    </h3>
    <p>
        Which <a href="https://en.wikipedia.org/wiki/Object%E2%80%93relational_mapping">object-relational mapper</a> (ORM) should you learn? <a href="https://hibernate.org/orm/">Hibernate</a>? <a href="https://learn.microsoft.com/ef/">Entity Framework</a>?
    </p>
    <p>
        How about learning <a href="https://en.wikipedia.org/wiki/SQL">SQL</a>? I learned SQL in 1999, I believe, and it's served me well ever since. I <a href="/2023/09/18/do-orms-reduce-the-need-for-mapping">consider raw SQL to be more productive than using an ORM</a>. Again, knowing SQL is largely technology-independent. While each database typically has its own SQL dialect, the fundamentals are the same. I'm most well-versed in the <a href="https://en.wikipedia.org/wiki/Microsoft_SQL_Server">SQL Server</a> dialect, but I've also used my SQL knowledge to interact with <a href="https://www.oracle.com/database/">Oracle</a> and <a href="https://www.postgresql.org/">PostgreSQL</a>. Once you know one SQL dialect, you can quickly solve data problems in one of the other dialects.
    </p>
    <p>
        It doesn't matter much whether you're interacting with a database from .NET, Haskell, Python, Ruby, or another language. SQL is not only universal, the core of the language is stable. What I learned in 1999 is still useful today. Can you say the same about your current ORM?
    </p>
    <p>
        Most programmers prefer learning the newest, most cutting-edge technology, but that's a risky gamble. Once upon a time <a href="https://en.wikipedia.org/wiki/Microsoft_Silverlight">Silverlight</a> was a cutting-edge technology, and more than one of my contemporaries went all-in on it.
    </p>
    <p>
        On the contrary, most programmers find old stuff boring. It turns out, though, that it may be worthwhile learning some old technologies like SQL. Be aware of the <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy effect</a>. If it's been around for a long time, it's likely to still be around for a long time. This is true for the next example as well.
    </p>
    <h3 id="e4a7c033c0964420a0abbf83a0bbb773">
        HTTP <a href="#e4a7c033c0964420a0abbf83a0bbb773">#</a>
    </h3>
    <p>
        The <a href="https://en.wikipedia.org/wiki/HTTP">HTTP protocol</a> has been around since 1991. It's an effectively text-based protocol, and you can easily engage with a web server on a near-protocol level. This is true for other older protocols as well.
    </p>
    <p>
        In my first IT job in the late 1990s, one of my tasks was to set up and maintain <a href="https://en.wikipedia.org/wiki/Microsoft_Exchange_Server">Exchange Servers</a>. It was also my responsibility to make sure that email could flow not only within the organization, but that we could exchange email with the rest of the internet. In order to test my mail servers, I would often just <a href="https://en.wikipedia.org/wiki/Telnet">telnet</a> into them on port 25 and type in the correct, text-based instructions to send a test email.
    </p>
    <p>
        Granted, it's not that easy to telnet into a modern web server on port 80, but a ubiquitous tool like <a href="https://curl.se/">curl</a> accomplishes the same goal. I recently wrote how <a href="/2024/05/13/gratification">knowing curl is better</a> than knowing <a href="https://www.postman.com/">Postman</a>. While this wasn't meant as an attack on Postman specifically, neither was it meant as a facile claim that curl is the only tool useful for ad-hoc interaction with HTTP-based APIs. Sometimes you only realize an underlying truth when you write about a thing and then <a href="https://blog.ploeh.dk/2024/05/13/gratification/#9efea1cadb8c4e388bfba1a2064dd59a">other people find fault with your argument</a>. The underlying truth, I think, is that it pays to understand HTTP and being able to engage with an HTTP-based web service at that level of abstraction.
    </p>
    <p>
        Preferably in an automatable way.
    </p>
    <h3 id="e3a250b707b243dabc6609134e864aee">
        Shells and scripting <a href="#e3a250b707b243dabc6609134e864aee">#</a>
    </h3>
    <p>
        The reason I favour curl over other tools to interact with HTTP is that I already spend quite a bit of time at the command line. I typically have a little handful of terminal windows open on my laptop. If I need to test an HTTP server, curl is already available.
    </p>
    <p>
        Many years ago, an employer introduced me to <a href="https://git-scm.com/">Git</a>. Back then, there were no good graphical tools to interact with Git, so I had to learn to use it from the command line. I'm eternally grateful that it turned out that way. I still use Git from the command line.
    </p>
    <p>
        When you install Git, by default you also install Git Bash. Since I was already using that shell to interact with Git, it began to dawn on me that it's a full-fledged shell, and that I could do all sorts of other things with it. It also struck me that learning <a href="https://www.gnu.org/software/bash/">Bash</a> would be a better investment of my time than learning <a href="https://learn.microsoft.com/powershell/">PowerShell</a>. At the time, there was no indication that PowerShell would ever be relevant outside of Windows, while Bash was already available on most systems. Even today, knowing Bash strikes me as more useful than knowing PowerShell.
    </p>
    <p>
        It's not that I do much Bash-scripting, but I could. Since I'm a programmer, if I need to automate something, I naturally reach for something more robust than shell scripting. Still, it gives me confidence to know that, since I already know Bash, Git, curl, etc., I <em>could</em> automate some tasks if I needed to.
    </p>
    <p>
        Many a reader will probably complain that the Git CLI has horrible <a href="/2024/05/13/gratification">developer experience</a>, but I will, again, postulate that it's not that bad. It helps if you understand some fundamentals.
    </p>
    <h3 id="a511cfd8d9bf4bbda433dbf70184284a">
        Algorithms and data structures <a href="#a511cfd8d9bf4bbda433dbf70184284a">#</a>
    </h3>
    <p>
        Git really isn't that difficult to understand once you realize that a Git repository is just a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">directed acyclic graph</a> (DAG), and that branches are just labels that point to nodes in the graph. There are basic data structures that it's just useful to know. DAGs, <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">trees</a>, <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a> in general, <a href="https://en.wikipedia.org/wiki/Adjacency_list">adjacency lists</a> or <a href="https://en.wikipedia.org/wiki/Adjacency_matrix">adjacency matrices</a>.
    </p>
    <p>
        Knowing that such data structures exist is, however, not that useful if you don't know what you can <em>do</em> with them. If you have a graph, you can find a <a href="https://en.wikipedia.org/wiki/Minimum_spanning_tree">minimum spanning tree</a> or a <a href="https://en.wikipedia.org/wiki/Shortest-path_tree">shortest-path tree</a>, which sometimes turn out to be useful. Adjacency lists or matrices give you ways to represent graphs in code, which is why they are useful.
    </p>
    <p>
        Contrary to certain infamous interview practices, you don't need to know these algorithms by heart. It's usually enough to know that they exist. I can't remember <a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm">Dijkstra's algorithm</a> off the top of my head, but if I encounter a problem where I need to find the shortest path, I can look it up.
    </p>
    <p>
        Or, if presented with the problem of constructing current state from an Event Store, you may realize that it's just a left <a href="https://en.wikipedia.org/wiki/Fold_(higher-order_function)">fold</a> over a <a href="https://en.wikipedia.org/wiki/Linked_list">linked list</a>. (This isn't my own realization; I first heard it from <a href="https://gotocon.com/cph-2011/presentation/Behavior!">Greg Young in 2011</a>.)
    </p>
    <p>
        Now we're back at one of the first examples, that of FP knowledge. A <a href="/2019/05/27/list-catamorphism">list fold is its catamorphism</a>. Again, these things are much easier to learn if you already know some fundamentals.
    </p>
    <h3 id="f109425f27014cd5bd395a74e9575355">
        What to learn <a href="#f109425f27014cd5bd395a74e9575355">#</a>
    </h3>
    <p>
        These examples may seems overwhelming. Do you really need to know all of that before things become easier?
    </p>
    <p>
        No, that's not the point. I didn't start out knowing all these things, and some of them, I'm still not very good at. The point is rather that if you're wondering how to invest your limited time so that you can remain up to date, consider pursuing general-purpose knowledge rather than learning a specific technology.
    </p>
    <p>
        Of course, if your employer asks you to use a particular library or programming language, you need to study <em>that</em>, if you're not already good at. If, on the other hand, you decide to better yourself, you can choose what to learn next.
    </p>
    <p>
        Ultimately, if your're learning for your own sake, the most important criterion may be: Choose something that interests you. If no-one forces you to study, keeping at it is easier if the topic engages you.
    </p>
    <p>
        If, however, you have the choice between learning <a href="https://mjvl.github.io/Noun.js/">Noun.js</a> or design patterns, may I suggest the latter?
    </p>
    <h3 id="94c3f380b556403d82dd9f3cd0c1d1e9">
        For life <a href="#94c3f380b556403d82dd9f3cd0c1d1e9">#</a>
    </h3>
    <p>
        When are you done, you ask?
    </p>
    <p>
        Never. There's more stuff than you can learn in a lifetime. I've met a lot of programmers who finally give up on the grind to keep up, and instead become managers.
    </p>
    <p>
        As if there's nothing to learn when you're a manager. I'm fortunate that, before <a href="/2011/11/08/Independency">I went solo</a>, I mainly had good managers. I'm under no illusion that they automatically became good managers. All I've heard said about management is that there's a lot to learn in that field, too. Really, it'd be surprising if that wasn't the case.
    </p>
    <p>
        I can understand, however, how just keep learning the next library, the next framework, the next tool becomes tiring. As I've already outlined, I hit that wall more than a decade ago.
    </p>
    <p>
        On the other hand, there are so many wonderful fundamentals that you can learn. You can do self-study, or you can enrol in a more formal programme if you have the opportunity. I'm currently following a course on compiler design. It's not that I expect to pivot to writing compilers for the rest of my career, but rather,
    </p>
    <blockquote>
        <ol type="a">
            <li>"It is considered a topic that you should know in order to be "well-cultured" in computer science.</li>
            <li>"A good craftsman should know his tools, and compilers are important tools for programmers and computer scientists.</li>
            <li>"The techniques used for constructing a compiler are useful for other purposes as well.</li>
            <li>"There is a good chance that a programmer or computer scientist will need to write a compiler or interpreter for a domain-specific language."</li>
        </ol>
        <footer><cite><a href="/ref/introduction-to-compiler-design">Introduction to Compiler Design</a></cite> (from the introduction), Torben Ã†gidius Mogensen</footer>
    </blockquote>
    <p>
        That's good enough for me, and so far, I'm enjoying the course (although it's also hard work).
    </p>
    <p>
        You may not find this particular topic interesting, but then hopefully you can find something else that you fancy. 3D rendering? Machine learning? Distributed systems architecture?
    </p>
    <h3 id="7519e9b6147d49379f545c69871c381a">
        Conclusion <a href="#7519e9b6147d49379f545c69871c381a">#</a>
    </h3>
    <p>
        Technology moves at a pace with which it's impossible to keep up. It's not just you who's falling behind. Everyone is. Even the best-paid <a href="https://en.wikipedia.org/wiki/Big_Tech">GAMMA</a> programmer knows next to nothing of all there is to know in the field. They may have superior skills in certain areas, but there will be so much other stuff that they don't know.
    </p>
    <p>
        You may think of me as a <a href="https://x.com/hillelogram/status/1445435617047990273">thought leader</a> if you will. If nothing else, I tend to be a prolific writer. Perhaps you even think I'm a good programmer. I should hope so. Who fancies themselves bad at something?
    </p>
    <p>
        You should, however, have seen me struggle with <a href="https://en.wikipedia.org/wiki/C_(programming_language)">C</a> programming during a course on computer systems programming. There's a thing I'm happy if I never have to revisit.
    </p>
    <p>
        You can't know it all. You can't keep up. But you can focus on learning the fundamentals. That tends to make it easier to learn specific technologies that build on those foundations.
    </p>
</div>