---
layout: post
title: "Using NuGet with autonomous repositories"
description: "NuGet is a great tool if used correctly. Here's one way to do it."
date: 2014-02-03 16:06 UTC
tags: [Productivity]
image: "/content/binary/pub-sub-repositories.png"
image_alt: "Diagram showing pull and push from repositories."
---
{% include JB/setup %}

<div id="post">
	<p>
		<em>{{ page.description }}</em>
	</p>
	<p>
		In my <a href="/2014/01/29/nuget-package-restore-considered-harmful">recent post about NuGet</a>, I described why the Package Restore feature is insidious. As expected, this provoked some readers, who didn't like my recommendation of adding NuGet packages to source control. That's understandable; the problem with a rant like my previous post is that while it tells you what <em>not</em> to do, it's not particularly constructive. While I told you to store NuGet packages in your source control system, I didn't describe patterns for doing it effectively. My impression was that it's trivial to do this, but based on the reactions I got, I realize that this may not be the case. Could it be that some readers react strongly because they don't know what else to do (than to use NuGet Package Restore)? In this post, I'll describe a way to use and organize NuGet packages that have worked well for me in several organizations.
	</p>
	<h3 id="a4142d751602487d9958d355cd077b48">
		Publish/Subscribe <a href="#a4142d751602487d9958d355cd077b48" title="permalink">#</a>
	</h3>
	<p>
		In <a href="http://grean.com">Grean</a> we use NuGet in <em>a sort</em> of Publish/Subscribe style. This is a style I've also used in other organizations, to great effect. It's easy: create reusable components as autonomous libraries, and publish them as NuGet packages. If you don't feel like sharing your internal building blocks with the rest of the world, you can use a custom, internal package repository, or you can use <a href="http://www.myget.org">MyGet</a> (that's what we do in Grean).
	</p>
	<p>
		A reusable component may be some package you've created for internal use. Something that packages the way you authenticate, log, instrument, render, etc. in your organization.
	</p>
	<p>
		Every time you have a new version of one of your components (let's call it <em>C1</em>), you publish the NuGet package.
	</p>
	<p>
		<img src="/content/binary/pub-sub-repositories.png" alt="Diagram showing pull and push from repositories.">
	</p>
	<p>
		Just like other Publish/Subscribe systems, the only other party that you rely on at this moment is the queue/bus/broker - in this case the package repository, like NuGet.org or MyGet.org. No other systems need to be available to do this.
	</p>
	<p>
		You do this for every reusable component you want to publish. Each is independent of other components.
	</p>
	<h3 id="3f263a3838a9406082e55abc1794c118">
		Pull based on need <a href="#3f263a3838a9406082e55abc1794c118" title="permalink">#</a>
	</h3>
	<p>
		In addition to reusable components, you probably also build <em>systems</em>; that is, applications that actually <em>do</em> something. You probably build those systems on top of reusable components - yours, and other publicly available NuGet packages. Let's call one such system <em>S1</em>.
	</p>
	<p>
		Whenever you need a NuGet package (C1), you add it to the Visual Studio project where you need it, and then you <em>commit your changes</em> to that system's source control. It effectively means checking in the NuGet package, including all the binaries, to source control. However, the S1 repository is not the same repository as the C1 repository. Both are autonomous systems.
	</p>
	<p>
		The only system you need to be available when you add the NuGet package C1 is the NuGet package source (NuGet.org, MyGet.org, etc.). The only system you need to be available to commit the changes to S1 is your source control system, and if you use a <a href="http://en.wikipedia.org/wiki/Distributed_version_control_system">Distributed Version Control System</a> (DVCS), it's always going to be available.
	</p>
	<p>
		Pretty trivial so far.
	</p>
	<p>
		"This isn't pub/sub," you'll most likely say. That's right, not in the traditional sense. Still, if you adopt the pattern language of <a href="http://amzn.to/11Xr8Pn">Enterprise Integration Patterns</a>, you can think of yourself (and your colleagues) as a <a href="http://www.eaipatterns.com/PollingConsumer.html">Polling Consumer</a>.
	</p>
	<p>
		"But," I suppose you'll say, "I'm not polling the repository and pulling down every package ever published."
	</p>
	<p>
		True, but you could, and if you did, you'd most likely be filtering away most package updates, because they don't apply to your system. That corresponds to applying a <a href="http://www.eaipatterns.com/Filter.html">Message Filter</a>.
	</p>
	<p>
		This last part is important, so let me rephrase it:
	</p>
	<p>
		<blockquote>
			Just because your system uses a particular NuGet package, it doesn't mean that you have to install <em>every single version</em> ever published.
		</blockquote>
	</p>
	<p>
		It seems to me that at least some of the resistance to adding packages to your repository is based on something like that. As <a href="https://twitter.com/ursenzler">Urs Enzler</a> writes:
		<blockquote>
			[Putting packages in source control is] <a href="https://twitter.com/ursenzler/status/428969958228656128">"not an option if your repo grows > 100GB per month due to monthly updates of BIG nuget packages"</a>
		</blockquote>
		While I'm not at all in possession of all the facts regarding Urs Enzler's specific problems, it just got me thinking: do you really need to update your local packages every time a new package is published? You shouldn't have to, I think.
	</p>
	<p>
		As an example, consider my own open source project <a href="https://github.com/AutoFixture/AutoFixture">AutoFixture</a>, which keeps a fairly high release cadence. It's released according to the principles of <a href="http://en.wikipedia.org/wiki/Continuous_delivery">Continuous Delivery</a>, so every time there's a new feature or fix, we release a new NuGet package. In 2013, we released 47 versions of the <a href="https://www.nuget.org/packages/AutoFixture">AutoFixture NuGet package</a>, including one major release. That's almost a release every week, but while I use AutoFixture in many other projects, I don't try to keep up with it. I just install AutoFixture when I start a new project, and then I mostly update the package if I need one of the new features or bug fixes. Occasionally, I also update packages in order to not fall too much behind.
	</p>
	<p>
		As a publicly visible case, consider <a href="https://github.com/ploeh/Hyprlinkr">Hyprlinkr</a>, which uses AutoFixture as one of its dependencies. While going though Hyprlinkr's NuGet packages recently, I discovered that the Hyprlinkr code base was using AutoFixture 2.12.0 - an 18 months old version! I simply hadn't needed to update the package during that time. AutoFixture follows <a href="http://semver.org">Semantic Versioning</a>, and we go to great lengths to ensure that we don't break existing functionality (unless we do a major release).
	</p>
	<p>
		Use the NuGet packages you need, commit them to source control, and update them <em>as necessary</em>. For all well-designed packages, you should be able to skip versions without ill effects. This enables you to treat the code bases for each system (S1, S2, etc.) as <em>autonomous systems</em>. Everything you need in order to work with that code base is right there in the source code repository.
	</p>
	<h3 id="0368eb5d70414a5aae9b229378b40b77">
		Stable Dependency Principle <a href="#0368eb5d70414a5aae9b229378b40b77" title="permalink">#</a>
	</h3>
	<p>
		What if you need to keep up-to-date with a package that rapidly evolves? From Urs Enzler's <a href="https://twitter.com/ursenzler/status/428969958228656128">tweet</a>, I get the impression that this is the case not only for Urs, but for other people too. Imagine that the creator of such a package frequently publishes new versions, and that you <em>have</em> to keep up to date. If that's the case, it must imply that the package isn't stable, because otherwise, you'd be able to skip updates.
	</p>
	<p>
		Let me repeat that:
	</p>
	<p>
		<blockquote>
			If you depend on a NuGet package, and you <em>have</em> to stay up-to-date, it implies that the package is unstable.
		</blockquote>
	</p>
	<p>
		If this is the case, you have an entirely other problem on your hand. It has nothing to do with NuGet Package Restore, or whether you're keeping packages in source control or not. It means that you're violating the <a href="http://c2.com/cgi/wiki?StableDependenciesPrinciple">Stable Dependencies Principle</a> (SDP). If you feel pain in that situation, that's expected, but the solution isn't Package Restore, but a better dependency hierarchy.
	</p>
	<p>
		If you can invert the dependency, you can solve the problem. If you can't invert the dependency, you'd probably benefit from an <a href="http://amzn.to/WBCwx7">Anti-corruption Layer</a>. There are plenty of better solution that address the root cause of your problems. NuGet Package Restore, on the other hand, is only symptomatic relief.
	</p>
</div>

 <div id="comments">
  	<hr>
  	<h2 id="comments-header">
  		Comments
  	</h2>
	<div class="comment" id="9c28053ec9a04a29ae033cccf1272240">
  		<div class="comment-author">
  			<a href="http://stackoverflow.com/users/28298/chester89">Chermennov Gleb</a>
  		</div>
  		<div class="comment-content">
  			<p>
  				Can you elaborate a bit on not breaking existing functionality in newer versions (as long as they have one 
				major version)? What tools are you using to achieve that? I read your post on Semantic Versioning from 
				couple months ago. I manage OSS project and it has quite a big public API - each release I try hard to think of
				anything I or other contributors might have broken. Are you saying that you relay strictly on programmer 
				deep knowledge of the project when deciding on a new version number?
				Also, do you build AutoFixture or any other .NET project of yours for Linux/Mono?
  			</p>
  		</div>
  		<div class="comment-date">2014-02-03 19:00 UTC</div>
  	</div>  	
	<div class="comment" id="d38373917d054831adf8a811fe47e525">
  		<div class="comment-author">
  			<a href="">Mark Seemann</a>
  		</div>
  		<div class="comment-content">
  			<p>
  				For AutoFixture, as well as other OSS projects I maintain, we rely almost exclusively on unit tests, keeping in mind that <a href="/2013/04/02/why-trust-tests">trustworthy tests are append-only</a>. AutoFixture has some 4000+ unit tests, so if none of those break, I feel confident that a release doesn't contain breaking changes.
  			</p>
  			<p>
  				For my other OSS projects, the story is the same, although the numbers differ.
  				<ul>
  					<li><a href="https://github.com/ploeh/Albedo">Albedo</a> has 354 tests.</li>
  					<li><a href="https://github.com/ploeh/ZeroToNine">ZeroToNine</a> has 200 tests.</li>
  					<li><a href="https://github.com/ploeh/Hyprlinkr">Hyprlinkr</a> has 88 tests.</li>
  				</ul>
  				These are much smaller projects than AutoFixture, but since they were all built with TDD, they have excellent code coverage.
  			</p>
  			<p>
  				Currently, I don't build any of these .NET projects for Mono, as I've never had the need.
  			</p>
  		</div>
  		<div class="comment-date">2014-02-04 8:48 UTC</div>
  	</div>
	<div class="comment" id="3f4a947005ee481487c20b5face63df9">
		<div class="comment-author">
			<a href="http://stackoverflow.com/users/28298/chester89">Chermennov Gleb</a>
		</div>
		<div class="comment-content">
  			<p>
				So you verify behaviour didn't change with a help of automated tests and a good test coverage. What I had in mind
				is some technique to verify not only the desired behaviour is in place, but also a public API (method signatures, 
				class constructors, set of public types).
				I should probably clarify that in one of my projects public API is not fully covered by unit-tests. Most critical 
				parts of it are covered, but not all of it.
				Let's say that upcoming release contains bugfixes as well as new features. I also decided that couple of 
				public API methods are obsolete and deleted them. That makes a breaking change. Let's say I had a lot on my 
				mind and I forgot about the fact that I made those changes. Some time goes by, I'd like to push a new version 
				with all these changes to NuGet, but I'd like to double-check that the public API is still in place compared to the 
				last release. Are there some tools that help with that, may be the ones you use? Or do you rely fully on the tests 
				and your process in that regard? 
				My approach to releases and versioning is a LOT more error prone than yours, clearly, that's the part of my projects that 
				I'd like to improve.
			</p>
		</div>
		<div class="comment-date">2014-02-05 23:20 UTC</div>
	</div>
	<div class="comment" id="5b3707b39f17423da6766cbfe0d3f337">
  		<div class="comment-author">
  			<a href="">Mark Seemann</a>
  		</div>
  		<div class="comment-content">
  			<p>
  				The only technique I rely on apart from automated tests is code reviews. When I write code myself, I always keep in mind if I'm breaking anything. When I receive Pull Requests (PR), I always review them with an eye towards breaking changes. Basically, if a PR changes an existing test, I review it very closely. Obviously, any change that involves renaming of types or members, or that changes public method signatures, are out of the question.
  			</p>
  			<p>
  				While I'm not aware of any other technique than discipline that will protect against breaking changes, you could always try to check out the tests you have against a previous version, and see if they all pass against the new version. If they don't, you have a breaking change.
  			</p>
  			<p>
  				You can also make a diff of everything that's happened since your last release, and then meticulously look through all types and members to see if anything was renamed, or method signatures changed. This will also tell you if you have breaking changes.
  			</p>
  			<p>
  				However, in the end, if you find no breaking changes using these approaches, it's still not a guarantee that you have no breaking changes, because you may have changed the <em>behaviour</em> of some methods. Since you don't have full test coverage, it's hard to tell.
  			</p>
  			<p>
  				What you <em>could</em> try to do, is to have <a href="http://research.microsoft.com/en-us/projects/Pex">Pex</a> create a full test suite for your latest released version. This test suite will give you a full snapshot of the behaviour of that release. You could then try to run that test suite on your release candidate to see if anything changed. I haven't tried this myself, and I presume that there's still a fair bit of work involved, but perhaps it's worth a try.
  			</p>
  		</div>
  		<div class="comment-date">2014-02-06 14:51 UTC</div>
  	</div>
</div>