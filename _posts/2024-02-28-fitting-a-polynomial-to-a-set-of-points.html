---
layout: post
title: "Fitting a polynomial to a set of points"
description: "The story of a fiasco."
date: 2024-02-28 16:33 UTC
tags: [Languages]
image: "/content/binary/hype-8th-degree-poly.png"
image_alt: "Gartner hype cycle and a eighth-degree fitted polynomial."
---
{% include JB/setup %}

<div id="post">
    <p>
        <em>{{ page.description }}</em>
    </p>
    <p>
        This is the second in a small series of articles titled <a href="">Trying to fit the hype cycle</a>. In the introduction, I've described the exercise I had in mind: Determining a formula, or at least a <a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a> <a href="https://en.wikipedia.org/wiki/Function_(mathematics)">function</a>, for the <a href="https://en.wikipedia.org/wiki/Gartner_hype_cycle">Gartner hype cycle</a>. This, to be clear, is an entirely frivolous exercise with little practical application.
    </p>
    <p>
        In the previous article, I <a href="">extracted a set of <em>(x, y)</em> coordinates from a bitmap</a>. In this article, I'll showcase my failed attempt at fitting the data to a <a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>.
    </p>
    <h3 id="36f71204d90b44a8b39a7d8103f46cca">
        Failure <a href="#36f71204d90b44a8b39a7d8103f46cca">#</a>
    </h3>
    <p>
        I've already revealed that I failed to accomplish what I set out to do. Why should you read on, then?
    </p>
    <p>
        You don't have to, and I can't predict the many reasons my readers have for occasionally swinging by. Therefore, I can't tell you why <em>you</em> should keep reading, but I <em>can</em> tell you why I'm writing this article.
    </p>
    <p>
        This blog is a mix of articles that I write because readers ask me interesting questions, and partly, it's my personal research-and-development log. In that mode, I write about things that I've learned, and I write in order to learn. One can learn from failure as well as from success.
    </p>
    <p>
        I'm not <em>that</em> connected to 'the' research community (if such a thing exists), but I'm getting the sense that there's a general tendency in academia that researchers rarely publish their negative results. This could be a problem, because this means that the rest of us never learn about the <em>thousands of ways that don't work</em>.
    </p>
    <p>
        Additionally, in 'the' programming community, we also tend to boast of our victories and hide our failures. More than one podcast (sorry about the <a href="https://en.wikipedia.org/wiki/Weasel_word">weasel words</a>, but I don't remember which ones) have discussed how this gives young programmers the wrong impression of what programming is like. It is, indeed, a process of much trial and error, but usually, we only publish our polished, final result.
    </p>
    <p>
        Well, I did manage to produce code to fit a polynomial to the Gartner hype cycle, but I never managed to get a <em>good</em> fit.
    </p>
    <h3 id="34ad323fc07f48709fb86c4045bd5892">
        The big picture <a href="#34ad323fc07f48709fb86c4045bd5892">#</a>
    </h3>
    <p>
        I realize that I have a habit of burying the lede when I write technical articles. I don't know if I've picked up that tendency from <a href="https://fsharp.org/">F#</a>, which does demand that you define a value or function before you can use it. This, by the way, <a href="/2015/04/15/c-will-eventually-get-all-f-features-right">is a good feature</a>.
    </p>
    <p>
        Here, I'll try to do it the other way around, and start with the big picture:
    </p>
    <p>
        <pre>data&nbsp;=&nbsp;numpy.loadtxt(<span style="color:#a31515;">&#39;coords.txt&#39;</span>,&nbsp;delimiter=<span style="color:#a31515;">&#39;,&#39;</span>)
 
x&nbsp;=&nbsp;data[:,&nbsp;0]
t&nbsp;=&nbsp;data[:,&nbsp;1]
w&nbsp;=&nbsp;fit_polynomial(x,&nbsp;t,&nbsp;9)
 
plot_fit(x,&nbsp;t,&nbsp;w)</pre>
    </p>
    <p>
        This, by the way, is a <a href="https://www.python.org/">Python</a> script, and it opens with these imports:
    </p>
    <p>
        <pre><span style="color:blue;">import</span>&nbsp;numpy
<span style="color:blue;">import</span>&nbsp;matplotlib.pyplot&nbsp;<span style="color:blue;">as</span>&nbsp;plt</pre>
    </p>
    <p>
        The first line of code reads the <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV</a> file into the <code>data</code> variable. The first column in that file contains all the <em>x</em> values, and the second column the <em>y</em> values. <a href="/ref/rogers-girolami">The book</a> that I've been following uses <em>t</em> for the data, rather than <em>y</em>. (Now that I think about it, I believe that this may only be because it works from an example in which the data to be fitted are <a href="https://en.wikipedia.org/wiki/100_metres">100 m dash</a> times, denoted <em>t</em>.)
    </p>
    <p>
        Once the script has extracted the data, it calls the <code>fit_polynomial</code> function to produce a set of weights <code>w</code>. The constant <code>9</code> is the degree of polynomial to fit, although I think that I've made an off-by-one error so that the result is only a eighth-degree polynomial.
    </p>
    <p>
        Finally, the code plots the original data together with the polynomial:
    </p>
    <p>
        <img src="/content/binary/hype-8th-degree-poly.png" alt="Gartner hype cycle and a eighth-degree fitted polynomial.">
    </p>
    <p>
        The green dots are the <em>(x, y)</em> coordinates that I extracted in the previous article, while the red curve is the fitted eighth-degree polynomial. Even though we're definitely in the realm of over-fitting, it doesn't reproduce the Gartner hype cycle.
    </p>
    <p>
        I've even arrived at the value <code>9</code> after some trial and error. After all, I wasn't trying to do any real science here, so over-fitting is definitely allowed. Even so, <code>9</code> seems to be the best fit I can achieve. With lover values, like <code>8</code>, below, the curve deviates too much:
    </p>
    <p>
        <img src="/content/binary/hype-7th-degree-poly.png" alt="Gartner hype cycle and a seventh-degree fitted polynomial.">
    </p>
    <p>
        The value <code>10</code> looks much like <code>9</code>, but above that (<code>11</code>), the curve completely disconnects from the data, it seems:
    </p>
    <p>
        <img src="/content/binary/hype-10th-degree-poly.png" alt="Gartner hype cycle and a tenth-degree fitted polynomial.">
    </p>
    <p>
        I'm not sure why it does this, to be honest. I would have thought that the more degrees you added, the more (over-)fitted the curve would be. Apparently, this is not so, or perhaps I made a mistake in my code.
    </p>
    <h3 id="183834d3c95544d9a185b5ba84bba9a1">
        Calculating the weights <a href="#183834d3c95544d9a185b5ba84bba9a1">#</a>
    </h3>
    <p>
        The <code>fit_polynomial</code> function calculates the polynomial coefficients using a <a href="https://en.wikipedia.org/wiki/Linear_algebra">linear algebra</a> formula that I've found in at least two text books. Numpy makes it easy to invert, transpose, and multiply matrices, so the formula itself is just a one-liner. Here it is in the entire context of the function, though:
    </p>
    <p>
        <pre><span style="color:blue;">def</span>&nbsp;<span style="color:#2b91af;">fit_polynomial</span>(x,&nbsp;t,&nbsp;degree):
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#a31515;">&quot;&quot;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;a&nbsp;polynomial&nbsp;to&nbsp;the&nbsp;given&nbsp;data.
 
&nbsp;&nbsp;&nbsp;&nbsp;Parameters
&nbsp;&nbsp;&nbsp;&nbsp;----------
&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;:&nbsp;Array&nbsp;of&nbsp;shape&nbsp;[n_samples]
&nbsp;&nbsp;&nbsp;&nbsp;t&nbsp;:&nbsp;Array&nbsp;of&nbsp;shape&nbsp;[n_samples]
&nbsp;&nbsp;&nbsp;&nbsp;degree&nbsp;:&nbsp;degree&nbsp;of&nbsp;the&nbsp;polynomial
 
&nbsp;&nbsp;&nbsp;&nbsp;Returns
&nbsp;&nbsp;&nbsp;&nbsp;-------
&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;:&nbsp;Array&nbsp;of&nbsp;shape&nbsp;[degree&nbsp;+&nbsp;1]
&nbsp;&nbsp;&nbsp;&nbsp;&quot;&quot;&quot;</span>
 
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:green;">#&nbsp;This&nbsp;expansion&nbsp;creates&nbsp;a&nbsp;matrix,&nbsp;so&nbsp;we&nbsp;name&nbsp;that&nbsp;with&nbsp;an&nbsp;upper-case&nbsp;letter</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:green;">#&nbsp;rather&nbsp;than&nbsp;a&nbsp;lower-case&nbsp;letter,&nbsp;which&nbsp;is&nbsp;used&nbsp;for&nbsp;vectors.</span>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;=&nbsp;expand(x.reshape((<span style="color:blue;">len</span>(x),&nbsp;1)),&nbsp;degree)
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:blue;">return</span>&nbsp;numpy.linalg.inv(X.T&nbsp;@&nbsp;X)&nbsp;@&nbsp;X.T&nbsp;@&nbsp;t</pre>
    </p>
    <p>
        This may look daunting, but is really just two lines of code. The rest is <a href="https://en.wikipedia.org/wiki/Docstring">docstring</a> and a comment.
    </p>
    <p>
        The above-mentioned formula is the last line of code. The one before that expands the input data <code>t</code> from a simple one-dimensional array to a matrix of those values squared, cubed, etc. That's how you use the <a href="https://en.wikipedia.org/wiki/Least_squares">least squares</a> method if you want to fit it to a polynomial of arbitrary degree.
    </p>
    <h3 id="782c5cbd64de43878eea4a3ddfcdf755">
        Expansion <a href="#782c5cbd64de43878eea4a3ddfcdf755">#</a>
    </h3>
    <p>
        The <code>expand</code> function looks like this:
    </p>
    <p>
        <pre><span style="color:blue;">def</span>&nbsp;<span style="color:#2b91af;">expand</span>(x,&nbsp;degree):
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#a31515;">&quot;&quot;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;Expands&nbsp;the&nbsp;given&nbsp;array&nbsp;to&nbsp;polynomial&nbsp;elements&nbsp;of&nbsp;the&nbsp;given&nbsp;degree.
 
&nbsp;&nbsp;&nbsp;&nbsp;Parameters
&nbsp;&nbsp;&nbsp;&nbsp;----------
&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;:&nbsp;Array&nbsp;of&nbsp;shape&nbsp;[n_samples,&nbsp;1]
&nbsp;&nbsp;&nbsp;&nbsp;degree&nbsp;:&nbsp;degree&nbsp;of&nbsp;the&nbsp;polynomial
 
&nbsp;&nbsp;&nbsp;&nbsp;Returns
&nbsp;&nbsp;&nbsp;&nbsp;-------
&nbsp;&nbsp;&nbsp;&nbsp;Xp&nbsp;:&nbsp;Array&nbsp;of&nbsp;shape&nbsp;[n_samples,&nbsp;degree&nbsp;+&nbsp;1]
&nbsp;&nbsp;&nbsp;&nbsp;&quot;&quot;&quot;</span>
 
&nbsp;&nbsp;&nbsp;&nbsp;Xp&nbsp;=&nbsp;numpy.ones((<span style="color:blue;">len</span>(x),&nbsp;1))
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:blue;">for</span>&nbsp;i&nbsp;<span style="color:blue;">in</span>&nbsp;<span style="color:blue;">range</span>(1,&nbsp;degree&nbsp;+&nbsp;1):
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Xp&nbsp;=&nbsp;numpy.hstack((Xp,&nbsp;numpy.power(x,&nbsp;i)))
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:blue;">return</span>&nbsp;Xp</pre>
    </p>
    <p>
        The function begins by creating a column vector of ones, here illustrated with only three rows:
    </p>
    <p>
        <pre>&gt;&gt;&gt; Xp = numpy.ones((3, 1))
&gt;&gt;&gt; Xp
array([[1.],
       [1.],
       [1.]])</pre>
    </p>
    <p>
        It then proceeds to loop over as many degrees as you've asked it to, each time adding a column to the <code>Xp</code> matrix. Here's an example of doing that up to a power of three, on example input <code>[1,2,3]</code>:
    </p>
    <p>
        <pre>&gt;&gt;&gt; x = numpy.array([1,2,3]).reshape((3, 1))
&gt;&gt;&gt; x
array([[1],
       [2],
       [3]])
&gt;&gt;&gt; Xp = numpy.hstack((Xp, numpy.power(x, 1)))
&gt;&gt;&gt; Xp
array([[1., 1.],
       [1., 2.],
       [1., 3.]])
&gt;&gt;&gt; Xp = numpy.hstack((Xp, numpy.power(x, 2))) 
&gt;&gt;&gt; Xp
array([[1., 1., 1.],
       [1., 2., 4.],
       [1., 3., 9.]])
&gt;&gt;&gt; Xp = numpy.hstack((Xp, numpy.power(x, 3))) 
&gt;&gt;&gt; Xp
array([[ 1.,  1.,  1.,  1.],
       [ 1.,  2.,  4.,  8.],
       [ 1.,  3.,  9., 27.]])</pre>
    </p>
    <p>
        Once it's done looping, the <code>expand</code> function returns the resulting <code>Xp</code> matrix.
    </p>
    <h3 id="cfb27c6067d2486c95836dc61484b2a0">
        Plotting <a href="#cfb27c6067d2486c95836dc61484b2a0">#</a>
    </h3>
    <p>
        Finally, here's the <code>plot_fit</code> procedure:
    </p>
    <p>
        <pre><span style="color:blue;">def</span>&nbsp;<span style="color:#2b91af;">plot_fit</span>(x,&nbsp;t,&nbsp;w):
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#a31515;">&quot;&quot;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;Plots&nbsp;the&nbsp;polynomial&nbsp;with&nbsp;the&nbsp;given&nbsp;weights&nbsp;and&nbsp;the&nbsp;data.
 
&nbsp;&nbsp;&nbsp;&nbsp;Parameters
&nbsp;&nbsp;&nbsp;&nbsp;----------
&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;:&nbsp;Array&nbsp;of&nbsp;shape&nbsp;[n_samples]
&nbsp;&nbsp;&nbsp;&nbsp;t&nbsp;:&nbsp;Array&nbsp;of&nbsp;shape&nbsp;[n_samples]
&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;:&nbsp;Array&nbsp;of&nbsp;shape&nbsp;[degree&nbsp;+&nbsp;1]
&nbsp;&nbsp;&nbsp;&nbsp;&quot;&quot;&quot;</span>
 
&nbsp;&nbsp;&nbsp;&nbsp;xs&nbsp;=&nbsp;numpy.linspace(x[0],&nbsp;x[0]+<span style="color:blue;">len</span>(x),&nbsp;100)
&nbsp;&nbsp;&nbsp;&nbsp;ys&nbsp;=&nbsp;numpy.polyval(w[::-1],&nbsp;xs)
 
&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(xs,&nbsp;ys,&nbsp;<span style="color:#a31515;">&#39;r&#39;</span>)
&nbsp;&nbsp;&nbsp;&nbsp;plt.scatter(x,&nbsp;t,&nbsp;s=10,&nbsp;c=<span style="color:#a31515;">&#39;g&#39;</span>)
&nbsp;&nbsp;&nbsp;&nbsp;plt.show()</pre>
    </p>
    <p>
        This is fairly standard pyplot code, so I don't have much to say about it.
    </p>
    <h3 id="3730027db8614b01960cf5379d8add78">
        Conclusion <a href="#3730027db8614b01960cf5379d8add78">#</a>
    </h3>
    <p>
        When I started this exercise, I'd hoped that I could get close to the Gartner hype cycle by over-fitting the model to some ridiculous polynomial degree. This turned out not to be the case, for reasons that I don't fully understand. As I increase the degree, the curve begins to deviate from the data.
    </p>
    <p>
        I can't say that I'm a data scientist or a statistician of any skill, so it's possible that my understanding is still too shallow. Perhaps I'll return to this article later and marvel at the ineptitude on display here.
    </p>
</div>
